# 解法

- 基本的な戦略
- 利用特徴量
- seen 用 model の詳細
- unseen 用 model の詳細

について順番に記載します。

## 基本的な戦略

- 高次の接続情報を利用する

### seen ユーザーと unseen ユーザー用のモデルを２つ作る（CV や Fold の切り方について）

- **要約**：seen ユーザー用のモデルを作って seen ユーザーの予測をし、unseen ユーザー用のモデルを作って unseen ユーザーの予測をする。手元の CV score は、seen CV *0.77 + unseen CV* 0.23 で見積もる

詳細についてはすでにディスカッションに記載済みです。

- [オススメの Fold の切り方と信頼できるCVについての説明：seen と unseen ユーザー用に分ける](https://www.guruguru.science/competitions/21/discussions/3e3f5be8-7414-439a-b79f-f3d7e004d920/)

### 利用したモデルの簡単な説明

seen 用か unseen 用かで利用モデルは違うのですが

- LightGBM
- Neural Network
- Surprise などのExplicit Feedback 用の モデル
- LightGCN (seen 用)

などです。

## 利用特徴量

以下の特徴量は LightGBM や Neural Network で利用します。共通で利用しているものもあれば、片方でしか利用していないものもあります。

- 文字列からの情報
  - BERT等から得られた埋め込み表現
  - 編集距離、

- ユーザーごとに固有の情報
  - anime のテーブルデータを単純に結合しただけでは、そのアニメの情報は分かるが、そのユーザーの情報が分からない。よって、「そのユーザーがそのアニメをどう思うのか」の情報がないと予測がしにくくなる。
  - seen 用モデルであれば user_id (unseen用モデルでは使えない)
  - ユーザーごとに集約した特徴量（anime データの統計量）は unseen 用モデルであっても使える
- Implicit Feedback に対する協調フィルタリングの学習で得られた埋め込み表現
  - test にもある重要な情報としては、その行が存在するという「視聴した」という情報がある。これを利用しないともったいない
  - implicit というライブラリで、協調フィルタリング系の手法がいくつか使え、ユーザーとアイテムの埋め込み表現を結果的に得ることができる
  - train, test の user_id, anime_id のペア情報を結合して implicit で得られた埋め込み表現を特徴量として利用した

## 利用モデルの概要

## その他

### 特徴量管理

- 前処理した結果を feather 形式で一定の種類ごとに保存
- 学習で使うときは毎回特徴量を生成する必要がないので、多少の時短になるし管理がし易い

### 実験管理

- 利用パラメータや学習結果は wandb に保存して見やすく
- ローカルでは hydra でパラメータや使う特徴量を管理
- oof と submission ファイルは実験ごとに生成し、アンサンブルし易いように

悪くはなかったが、命名規則やパラメータ管理の方法を最初にちゃんと決めていなかったので、ごちゃごちゃしてしまった。再現できるようにする上、短期コンで時間があまりなかったのもあり、あとから修正をすることが難しかった。（ファイル名もパラメータも特徴量も wandb に保存しているので、修正しても再現自体はやろうと思えばできた）

hydra で特徴量を管理するファイルを作って、パラメータは実行時にオーバーライドするとかが良かったかもしれない。
