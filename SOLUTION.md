# 解法

- 基本的な戦略
- 利用特徴量
- seen 用 model の詳細
- unseen 用 model の詳細

について順番に記載します。

## 基本的な戦略

### CV や Fold の切り方 (seen ユーザーと unseen ユーザー用のモデルを２つ作る)

- **要約**：seen ユーザー用のモデルを作って seen ユーザーの予測をし、unseen ユーザー用のモデルを作って unseen ユーザーの予測をする。手元の CV score は、seen CV *0.77 + unseen CV* 0.23 で見積もる

詳細についてはすでにディスカッションに記載済みです。

- [オススメの Fold の切り方と信頼できるCVについての説明：seen と unseen ユーザー用に分ける](https://www.guruguru.science/competitions/21/discussions/3e3f5be8-7414-439a-b79f-f3d7e004d920/)

### アイデアを出す上で意識したこと

コンペ中盤くらいから意識していたことは、「視聴したという接続情報そのものを活用する」ことです。

test データには score 情報は存在しませんが、その作品を視聴したという情報自体が与えられています。
実務上はこのような状況は少ないですが、逆に言えばそこが独自の工夫しがいのある点と言えるとも思います。

特徴量や利用するモデルはこれらの情報を活用できるようなものをいくつか取り入れました。

### 利用したモデルの簡単な説明

seen 用か unseen 用かで利用モデルは違うのですが

- LightGBM
- Neural Network
- Surprise など Explicit Feedback 用の モデル
- LightGCN (seen 用)
- 独自の Graph Neural Network (seen 用)

などを用いました（詳細は後述）

## 利用特徴量

基本方針として、ユーザーごとに固有の情報を作れるようにしました。例えば、ユーザーごとに groupby で集約した特徴量（mean, max, min, sum, var 等、anime データの統計量）をたくさん作るようにしました。

anime のテーブルデータを単純に結合しただけでは、そのアニメの情報は分かりますが、そのユーザーの情報が分かりません。よって、「そのユーザーがそのアニメをどう思うのか」の情報がないと予測がしにくくなります。

以下の特徴量は LightGBM や Neural Network で利用します。共通で利用しているものもあれば、片方でしか利用していないものもあります。

- 文字列からの情報
  - BERT等から得られた埋め込み表現
  - その anime_id と類似した作品をそのユーザーがどれだけ見ているのかの情報（編集距離の統計量を取る）
  - "genres", "producers", "licensors", "studios" の Multi hot encoding。ユニーク数が多くなるので SVD で次元圧縮
- カテゴリ情報
  - One hot encoding: NN 用
  - Label encoding : LightGBM 用
- 作品に関係する人数（"members", "watching", "completed", "on_hold", "dropped", "plan_to_watch"）
  - userごとにgroupbyした特徴量をさらにanimeごとにgroupbyするなど、2hop,3hop先の情報を特徴量として取得できるように工夫してみたが、1hop先だけでも十分だったかもしれない
  - 特徴量的には一番効いていそう
- Airedから抽出した年情報、Durationから抽出した時間情報、
- Implicit Feedback に対する協調フィルタリングの学習で得られた埋め込み表現
  - test にもある重要な情報としては、その行が存在するという「視聴した」という情報がある。これを利用しないともったいない
  - implicit というライブラリで、協調フィルタリング系の手法がいくつか使え、ユーザーとアイテムの埋め込み表現を結果的に得ることができる
  - train, test の user_id, anime_id のペア情報を結合して implicit で得られた埋め込み表現を特徴量として利用

また、seen用かunseen用かで使う特徴量を一部注意を払う必要があります。

- user_id を label encoding などして直接使えるのは seen 用モデルのみ (unseen用モデルでは、推論時に学習していない id が出現するので使えない)
- ユーザーごとに集約した特徴量（anime データの統計量）は unseen 用モデルであっても使える

## 利用モデルの概要

## その他

### 特徴量管理

- 前処理した結果を feather 形式で一定の種類ごとに保存
- 学習で使うときは毎回特徴量を生成する必要がないので、多少の時短になるし管理がし易い

### 実験管理

- 利用パラメータや学習結果は wandb に保存して見やすく
- ローカルでは hydra でパラメータや使う特徴量を管理
- oof と submission ファイルは実験ごとに生成し、アンサンブルし易いように

悪くはなかったのですが、命名規則やパラメータ管理の方法を最初にちゃんと決めていなかったのでごちゃごちゃしてしまいました。再現できるようにする上、短期コンで時間があまりなかったのもありあとから修正をするのは諦めました。（一応ファイル名もパラメータも特徴量も wandb に保存しているので、修正しても再現自体はやろうと思えばできましたが）

hydra で特徴量を管理するファイルを作って、パラメータは実行時にオーバーライドするとかでも良かったかもしれないです。
