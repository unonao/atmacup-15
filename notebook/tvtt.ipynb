{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47bff823-c44c-4c8a-b458-c456a989ae2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "import implicit\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hydra import compose, initialize\n",
    "from scipy.sparse import csr_matrix, random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 最大表示列数の指定（ここでは50列を指定）\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "from utils import evaluate_score, load_datasets, load_sample_sub, load_target\n",
    "from utils.embedding import TextEmbedder\n",
    "\n",
    "with initialize(config_path=\"../yamls\", version_base=None):\n",
    "    config = compose(config_name=\"config.yaml\")\n",
    "config.debug = True\n",
    "\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df69d7d1-841e-43de-97bf-8d8e5e722bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from glob import glob\n",
    "from typing import Any, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from timm.utils import AverageMeter\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers=2,\n",
    "        hidden_size: int = 64,\n",
    "        nhead: int = 4,\n",
    "        dim_feedforward: int = 1024,\n",
    "    ):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # embedding\n",
    "        self.user_embedding = nn.Embedding(2000, hidden_size)\n",
    "        self.anime_embedding = nn.Embedding(2000, hidden_size)\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=hidden_size,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=dim_feedforward,\n",
    "                dropout=0.0,\n",
    "                batch_first=True,\n",
    "            ),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        user_x = self.user_embedding(x[:, 0:1])\n",
    "        anime_x = self.anime_embedding(x[:, 1:])  # 修正\n",
    "        x = torch.cat([user_x, anime_x], dim=1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        output = self.fc(x).squeeze(2)\n",
    "        return output\n",
    "\n",
    "    def get_losses(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        mode_tensor: torch.Tensor,\n",
    "        mode: int = 1,\n",
    "    ) -> float:\n",
    "        loss_fn = nn.MSELoss()\n",
    "        loss = loss_fn(input[mode_tensor == mode], target[mode_tensor == mode])\n",
    "        loss = torch.sqrt(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e71d87-93f5-4d7c-9adc-6ec82317462c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(config.seed)\n",
    "output_path = Path(f\".\")\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6ee8420-fe3d-446e-8804-50adbd6b27fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path(config.input_path) / \"train.csv\")\n",
    "test_df = pd.read_csv(Path(config.input_path) / \"test.csv\")\n",
    "anime = pd.read_csv(Path(config.input_path) / \"anime.csv\")\n",
    "train_user_ids = load_target(\"user_id\")\n",
    "sub = load_sample_sub()\n",
    "\n",
    "\n",
    "if config.debug:\n",
    "    sample_index = train_df.sample(100).index\n",
    "    train_df = train_df.iloc[sample_index].reset_index(drop=True)\n",
    "    test_df = test_df.head(100)\n",
    "    train_user_ids = train_user_ids.iloc[sample_index].reset_index(drop=True)\n",
    "    sub = sub.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35a6f9-7a0e-4257-a76f-987dceeb4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Dataset & Model\n",
    "# =========================\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self, merge_df: pd.DataFrame, max_padding: int = 531):\n",
    "        \"\"\"\n",
    "        merge_df: すべてのデータを結合したもの。以下のカラムを持つ。\n",
    "        - \n",
    "        \"\"\"\n",
    "        self.merge_df = merge_df\n",
    "        self.max_padding = max_padding\n",
    "        self.user2anime_dict = merge_df.groupby(\"ordinal_user_id\")[\"ordinal_anime_id\"].apply(list).to_dict()\n",
    "        self.user2mode_dict = merge_df.groupby(\"ordinal_user_id\")[\"ordinal_mode\"].apply(list).to_dict()\n",
    "        self.user2score = merge_df.groupby(\"ordinal_user_id\")[\"score\"].apply(list).to_dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.merge_df[\"ordinal_user_id\"].nunique()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        出力したいもの\n",
    "        - input_tensor: user_id, anime_id 系列　を結合したもの\n",
    "        - mode_tensor: user_idか、train用の anime_id か、validation用のanime_idか、test用のanime_id かを判断するためのもの。\n",
    "        損失計算の対象を決めるために設定する。{user_id: 0, train:1, valid:2, test:3}\n",
    "        - attention_mask: 計算対象外のpaddingの位置をtransformerに教えるために必要\n",
    "        - score_tensor: ラベルとなるスコア情報。ラベルが無いものは適当に0で埋めるが使わない\n",
    "        \"\"\"\n",
    "        user_tensor = torch.Tensor([idx]).int()\n",
    "        anime_tensor = torch.Tensor(self.user2anime_dict[idx]).int()\n",
    "        mode_tensor = torch.Tensor(self.user2mode_dict[idx]).int()\n",
    "        score_tensor = torch.Tensor(self.user2score[idx]).float()\n",
    "\n",
    "        attention_mask = torch.zeros([self.max_padding + 1, self.max_padding + 1], dtype=torch.bool)\n",
    "        attention_mask[: anime_tensor.size(0) + 1, : anime_tensor.size(0) + 1] = True\n",
    "\n",
    "        pad_length = self.max_padding - anime_tensor.size(0)\n",
    "        input_tensor = torch.cat((user_tensor, anime_tensor, torch.zeros(pad_length, dtype=torch.int32)))\n",
    "        mode_tensor = torch.cat(\n",
    "            (\n",
    "                torch.zeros(1, dtype=torch.int32),\n",
    "                mode_tensor,\n",
    "                torch.zeros(pad_length, dtype=torch.int32),\n",
    "            )\n",
    "        )\n",
    "        score_tensor = torch.cat(\n",
    "            (\n",
    "                torch.zeros(1, dtype=torch.float),\n",
    "                score_tensor,\n",
    "                torch.zeros(pad_length, dtype=torch.float),\n",
    "            )\n",
    "        )\n",
    "        sample = {\n",
    "            \"input_tensor\": input_tensor,\n",
    "            \"mode_tensor\": mode_tensor,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"score_tensor\": score_tensor,\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669efd6-aaa7-43fc-9394-a19b3c045e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred = np.zeros(X_train_all.shape[0])\n",
    "test_preds = []\n",
    "\n",
    "\n",
    "kf = StratifiedGroupKFold(n_splits=config.nn.num_folds, shuffle=True, random_state=config.seed)\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(train_df, train_df[\"score\"], train_user_ids)):\n",
    "    print(f\"Fold {fold} start !\")\n",
    "\n",
    "    # ここで、userをtrainとvalidに分ける"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
