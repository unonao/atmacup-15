{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47bff823-c44c-4c8a-b458-c456a989ae2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "import implicit\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hydra import compose, initialize\n",
    "from scipy.sparse import csr_matrix, random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 最大表示列数の指定（ここでは50列を指定）\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "from utils import evaluate_score, load_datasets, load_sample_sub, load_target\n",
    "from utils.embedding import TextEmbedder\n",
    "\n",
    "with initialize(config_path=\"../yamls\", version_base=None):\n",
    "    config = compose(config_name=\"config.yaml\")\n",
    "config.debug = True\n",
    "\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df69d7d1-841e-43de-97bf-8d8e5e722bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from glob import glob\n",
    "from typing import Any, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from timm.utils import AverageMeter\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self, merge_df: pd.DataFrame, max_padding: int = 531):\n",
    "        \"\"\"\n",
    "        merge_df: すべてのデータを結合したもの。以下のカラムを持つ。\n",
    "        - user_label: 0-indexed にした user_id\n",
    "        - anime_label: 0-indexed にした anime_id\n",
    "        - mode: その行について trainは1, validationは2, testは3 にしたもの\n",
    "        - score: testに関しては適当な値(0)で良い\n",
    "        \"\"\"\n",
    "        self.merge_df = merge_df\n",
    "        self.max_padding = max_padding\n",
    "        self.user2anime_dict = merge_df.groupby(\"user_label\")[\"anime_label\"].apply(list).to_dict()\n",
    "        self.user2mode_dict = merge_df.groupby(\"user_label\")[\"mode\"].apply(list).to_dict()\n",
    "        self.user2score = merge_df.groupby(\"user_label\")[\"score\"].apply(list).to_dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.merge_df[\"user_label\"].nunique()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        出力したいもの\n",
    "        - input_tensor: user_id, anime_id 系列　を結合したもの\n",
    "        - mode_tensor: user_idか、train用の anime_id か、validation用のanime_idか、test用のanime_id かを判断するためのもの。\n",
    "        損失計算の対象を決めるために設定する。{user_id: 0, train:1, valid:2, test:3}\n",
    "        - attention_mask: 計算対象外のpaddingの位置をtransformerに教えるために必要\n",
    "        - score_tensor: ラベルとなるスコア情報。ラベルが無いものは適当に0で埋めるが使わない\n",
    "        \"\"\"\n",
    "        user_tensor = torch.Tensor([idx]).int()\n",
    "        anime_tensor = torch.Tensor(self.user2anime_dict[idx]).int()\n",
    "        mode_tensor = torch.Tensor(self.user2mode_dict[idx]).int()\n",
    "        score_tensor = torch.Tensor(self.user2score[idx]).float()\n",
    "\n",
    "        # ランダムに順序を変更する\n",
    "        indices = torch.randperm(anime_tensor.size(0))\n",
    "        anime_tensor = anime_tensor[indices]\n",
    "        mode_tensor = mode_tensor[indices]\n",
    "        score_tensor = score_tensor[indices]\n",
    "\n",
    "        pad_length = self.max_padding - anime_tensor.size(0)\n",
    "\n",
    "        # unseen用 (user_tensorは入れない）\n",
    "        attention_mask = torch.zeros([self.max_padding, self.max_padding], dtype=torch.bool)\n",
    "        attention_mask[: anime_tensor.size(0), : anime_tensor.size(0)] = True\n",
    "        input_tensor = torch.cat((anime_tensor, torch.zeros(pad_length, dtype=torch.int32)))\n",
    "        mode_tensor = torch.cat(\n",
    "            (\n",
    "                mode_tensor,\n",
    "                torch.zeros(pad_length, dtype=torch.int32),\n",
    "            )\n",
    "        )\n",
    "        score_tensor = torch.cat(\n",
    "            (\n",
    "                score_tensor,\n",
    "                torch.zeros(pad_length, dtype=torch.float),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        # seen用\n",
    "        attention_mask = torch.zeros([self.max_padding + 1, self.max_padding + 1], dtype=torch.bool)\n",
    "        attention_mask[: anime_tensor.size(0) + 1, : anime_tensor.size(0) + 1] = True\n",
    "        input_tensor = torch.cat((user_tensor, anime_tensor, torch.zeros(pad_length, dtype=torch.int32)))\n",
    "        mode_tensor = torch.cat(\n",
    "            (\n",
    "                torch.zeros(1, dtype=torch.int32),\n",
    "                mode_tensor,\n",
    "                torch.zeros(pad_length, dtype=torch.int32),\n",
    "            )\n",
    "        )\n",
    "        score_tensor = torch.cat(\n",
    "            (\n",
    "                torch.zeros(1, dtype=torch.float),\n",
    "                score_tensor,\n",
    "                torch.zeros(pad_length, dtype=torch.float),\n",
    "            )\n",
    "        )\n",
    "        \"\"\"\n",
    "        sample = {\n",
    "            \"input_tensor\": input_tensor,\n",
    "            \"mode_tensor\": mode_tensor,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"score_tensor\": score_tensor,\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers=2,\n",
    "        hidden_size: int = 64,\n",
    "        nhead: int = 4,\n",
    "        dim_feedforward: int = 1024,\n",
    "    ):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # embedding\n",
    "        self.user_embedding = nn.Embedding(2000, hidden_size)\n",
    "        self.anime_embedding = nn.Embedding(2000, hidden_size)\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=hidden_size,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=dim_feedforward,\n",
    "                dropout=0.0,\n",
    "                batch_first=True,\n",
    "            ),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.fc = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.anime_embedding(x[:, :])\n",
    "        \"\"\" seen用\n",
    "        user_x = self.user_embedding(x[:, 0:1])\n",
    "        anime_x = self.anime_embedding(x[:, 1:])\n",
    "        x = torch.cat([user_x, anime_x], dim=1)\n",
    "        \"\"\"\n",
    "        x = self.transformer_encoder(x)\n",
    "        output = self.fc(x).squeeze(2)\n",
    "        return output\n",
    "\n",
    "    def get_losses(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        mode_tensor: torch.Tensor,\n",
    "        mode: int = 1,\n",
    "    ) -> float:\n",
    "        loss_fn = nn.MSELoss()\n",
    "        loss = loss_fn(input[mode_tensor == mode], target[mode_tensor == mode])\n",
    "        loss = torch.sqrt(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e71d87-93f5-4d7c-9adc-6ec82317462c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(config.seed)\n",
    "output_path = Path(f\".\")\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6ee8420-fe3d-446e-8804-50adbd6b27fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path(config.input_path) / \"train.csv\")\n",
    "test_df = pd.read_csv(Path(config.input_path) / \"test.csv\")\n",
    "anime = pd.read_csv(Path(config.input_path) / \"anime.csv\")\n",
    "train_user_ids = load_target(\"user_id\")\n",
    "sub = load_sample_sub()\n",
    "\n",
    "if config.debug:\n",
    "    n = 1000\n",
    "    sample_index = train_df.sample(n).index\n",
    "    train_df = train_df.iloc[sample_index].reset_index(drop=True)\n",
    "    test_df = test_df.head(n)\n",
    "    train_user_ids = train_user_ids.iloc[sample_index].reset_index(drop=True)\n",
    "    sub = sub.head(n)\n",
    "\n",
    "\n",
    "# Merge the train data with the anime meta data\n",
    "all_df = pd.concat([train_df, test_df]).reset_index(drop=True)\n",
    "\n",
    "# 0-indexedの連番にする\n",
    "all_df[\"user_label\"], user_idx = pd.factorize(all_df[\"user_id\"])\n",
    "all_df[\"anime_label\"], anime_idx = pd.factorize(all_df[\"anime_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35a6f9-7a0e-4257-a76f-987dceeb4624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d669efd6-aaa7-43fc-9394-a19b3c045e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 start !\n"
     ]
    }
   ],
   "source": [
    "oof_df = train_df[[\"user_id\", \"anime_id\"]].copy()\n",
    "test_preds_df = test_df[[\"user_id\", \"anime_id\"]].copy()\n",
    "\n",
    "all_df[\"mode\"] = 0  # 初期化\n",
    "\n",
    "kf = StratifiedGroupKFold(n_splits=config.nn.num_folds, shuffle=True, random_state=config.seed)\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(train_df, train_df[\"score\"], train_user_ids)):\n",
    "    print(f\"Fold {fold} start !\")\n",
    "\n",
    "    # ここで、trainとvalidに分ける。foldごとにデータセットを作らないとおかしくなるので注意\n",
    "    # all_df[:len(train_df)] までのデータのmodeを決定\n",
    "    all_df.loc[train_index, \"mode\"] = 1\n",
    "    all_df.loc[valid_index, \"mode\"] = 2\n",
    "    # all_df[len(train_df):] のデータのmode (test) を埋める\n",
    "    all_df.loc[len(train_df) :, \"mode\"] = 3\n",
    "\n",
    "    dataset = UserDataset(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c11e840-67dc-4180-9d0c-472dc5270f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Dataset & Model\n",
    "# =========================\n",
    "\n",
    "dataset = UserDataset(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a3316-ab0f-4b1e-afea-e9ba094b6271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
