{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b53dd9f2-80ba-44c7-b5a5-5afe3cfe0888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "import implicit\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 最大表示列数の指定（ここでは50列を指定）\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "from hydra import compose, initialize\n",
    "\n",
    "from utils import load_datasets\n",
    "from utils.embedding import TextEmbedder\n",
    "\n",
    "with initialize(config_path=\"../yamls\", version_base=None):\n",
    "    config = compose(config_name=\"config.yaml\")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(Path(config.input_path) / \"train.csv\")\n",
    "test_df = pd.read_csv(Path(config.input_path) / \"test.csv\")\n",
    "\n",
    "sample_submission_df = pd.read_csv(Path(config.input_path) / \"sample_submission.csv\")\n",
    "anime_df = pd.read_csv(Path(config.input_path) / \"anime.csv\")\n",
    "\n",
    "# 整形\n",
    "anime_df[\"genres\"] = anime_df[\"genres\"].str.replace(\" \", \"\")\n",
    "\n",
    "# Merge the train data with the anime meta data\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "all_df = all_df.merge(anime_df, on=\"anime_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d6edf-9df8-4a7e-b2ad-470efd9630fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "202d46f5-9048-4411-9878-6b0c03cc6c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Embedding, ModuleList\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.conv import LGConv\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.utils import is_sparse, to_edge_index\n",
    "\n",
    "device = \"cpu\"  # \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# make Data\n",
    "all_df = pd.concat([train_df[[\"user_id\", \"anime_id\"]], test_df[[\"user_id\", \"anime_id\"]]]).reset_index(drop=True)\n",
    "\n",
    "all_df[\"user_label\"], user_idx = pd.factorize(all_df[\"user_id\"])\n",
    "all_df[\"anime_label\"], anime_idx = pd.factorize(all_df[\"anime_id\"])\n",
    "all_df[\"is_train\"] = True\n",
    "all_df.loc[len(train_df) :, \"is_train\"] = False\n",
    "# userとanimeの番号が別になるようにずらす\n",
    "all_df[\"anime_label\"] += len(user_idx)\n",
    "num_nodes = len(user_idx) + len(anime_idx)\n",
    "edges = all_df[[\"user_label\", \"anime_label\"]].to_numpy()\n",
    "edge_index = torch.tensor(edges.T, dtype=torch.long).contiguous()\n",
    "data = Data(num_nodes=num_nodes, edge_index=edge_index).to(device)\n",
    "data.edge_weight = torch.ones(len(all_df)).contiguous().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ce86130-b870-4bbe-a962-65be22fa7bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "          ... \n",
       "254072    1997\n",
       "254073    1997\n",
       "254074    1997\n",
       "254075    1997\n",
       "254076    1997\n",
       "Name: user_label, Length: 254077, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[\"user_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39fccebd-3f18-4f2e-ba51-bb32351dc147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "476ae819-bc70-4433-9143-466b5acb5230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Embedding, ModuleList\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch_geometric.nn.conv import LGConv\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.utils import is_sparse, to_edge_index\n",
    "\n",
    "\n",
    "class LightGCN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        embedding_dim: int,\n",
    "        num_layers: int,\n",
    "        alpha: Optional[Union[float, Tensor]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if alpha is None:\n",
    "            alpha = 1.0 / (num_layers + 1)\n",
    "\n",
    "        if isinstance(alpha, Tensor):\n",
    "            assert alpha.size(0) == num_layers + 1\n",
    "        else:\n",
    "            alpha = torch.tensor([alpha] * (num_layers + 1))\n",
    "        self.register_buffer(\"alpha\", alpha)\n",
    "\n",
    "        self.embedding = Embedding(num_nodes, embedding_dim)\n",
    "        self.convs = ModuleList([LGConv(**kwargs) for _ in range(num_layers)])\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def get_embedding(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Returns the embedding of nodes in the graph.\"\"\"\n",
    "        x = self.embedding.weight\n",
    "        out = x * self.alpha[0]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index, edge_weight)\n",
    "            out = out + x * self.alpha[i + 1]\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_label_index: OptTensor = None,\n",
    "        edge_weight: OptTensor = None,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Computes rankings for pairs of nodes.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor or SparseTensor): Edge tensor specifying\n",
    "                the connectivity of the graph.\n",
    "            edge_label_index (torch.Tensor, optional): Edge tensor specifying\n",
    "                the node pairs for which to compute rankings or probabilities.\n",
    "                If :obj:`edge_label_index` is set to :obj:`None`, all edges in\n",
    "                :obj:`edge_index` will be used instead. (default: :obj:`None`)\n",
    "            edge_weight (torch.Tensor, optional): The weight of each edge in\n",
    "                :obj:`edge_index`. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        if edge_label_index is None:\n",
    "            if is_sparse(edge_index):\n",
    "                edge_label_index, _ = to_edge_index(edge_index)\n",
    "            else:\n",
    "                edge_label_index = edge_index\n",
    "\n",
    "        out = self.get_embedding(edge_index, edge_weight)\n",
    "\n",
    "        out_src = out[edge_label_index[0]]\n",
    "        out_dst = out[edge_label_index[1]]\n",
    "\n",
    "        return (out_src * out_dst).sum(dim=-1)\n",
    "\n",
    "    def predict_link(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_label_index: OptTensor = None,\n",
    "        edge_weight: OptTensor = None,\n",
    "        prob: bool = False,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Predict links between nodes specified in :obj:`edge_label_index`.\n",
    "\n",
    "        Args:\n",
    "            prob (bool, optional): Whether probabilities should be returned.\n",
    "                (default: :obj:`False`)\n",
    "        \"\"\"\n",
    "        pred = self(edge_index, edge_label_index, edge_weight).sigmoid()\n",
    "        return pred if prob else pred.round()\n",
    "\n",
    "    def recommend(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "        src_index: OptTensor = None,\n",
    "        dst_index: OptTensor = None,\n",
    "        k: int = 1,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Get top-:math:`k` recommendations for nodes in :obj:`src_index`.\n",
    "\n",
    "        Args:\n",
    "            src_index (torch.Tensor, optional): Node indices for which\n",
    "                recommendations should be generated.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "                (default: :obj:`None`)\n",
    "            dst_index (torch.Tensor, optional): Node indices which represent\n",
    "                the possible recommendation choices.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "                (default: :obj:`None`)\n",
    "            k (int, optional): Number of recommendations. (default: :obj:`1`)\n",
    "        \"\"\"\n",
    "        out_src = out_dst = self.get_embedding(edge_index, edge_weight)\n",
    "\n",
    "        if src_index is not None:\n",
    "            out_src = out_src[src_index]\n",
    "\n",
    "        if dst_index is not None:\n",
    "            out_dst = out_dst[dst_index]\n",
    "\n",
    "        pred = out_src @ out_dst.t()\n",
    "        top_index = pred.topk(k, dim=-1).indices\n",
    "\n",
    "        if dst_index is not None:  # Map local top-indices to original indices.\n",
    "            top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
    "\n",
    "        return top_index\n",
    "\n",
    "    def link_pred_loss(self, pred: Tensor, edge_label: Tensor, **kwargs) -> Tensor:\n",
    "        r\"\"\"Computes the model loss for a link prediction objective via the\n",
    "        :class:`torch.nn.BCEWithLogitsLoss`.\n",
    "\n",
    "        Args:\n",
    "            pred (torch.Tensor): The predictions.\n",
    "            edge_label (torch.Tensor): The ground-truth edge labels.\n",
    "            **kwargs (optional): Additional arguments of the underlying\n",
    "                :class:`torch.nn.BCEWithLogitsLoss` loss function.\n",
    "        \"\"\"\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss(**kwargs)\n",
    "        return loss_fn(pred, edge_label.to(pred.dtype))\n",
    "\n",
    "    def recommendation_loss(\n",
    "        self,\n",
    "        pos_edge_rank: Tensor,\n",
    "        neg_edge_rank: Tensor,\n",
    "        node_id: Optional[Tensor] = None,\n",
    "        lambda_reg: float = 1e-4,\n",
    "        **kwargs,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Computes the model loss for a ranking objective via the Bayesian\n",
    "        Personalized Ranking (BPR) loss.\n",
    "\n",
    "        .. note::\n",
    "\n",
    "            The i-th entry in the :obj:`pos_edge_rank` vector and i-th entry\n",
    "            in the :obj:`neg_edge_rank` entry must correspond to ranks of\n",
    "            positive and negative edges of the same entity (*e.g.*, user).\n",
    "\n",
    "        Args:\n",
    "            pos_edge_rank (torch.Tensor): Positive edge rankings.\n",
    "            neg_edge_rank (torch.Tensor): Negative edge rankings.\n",
    "            node_id (torch.Tensor): The indices of the nodes involved for\n",
    "                deriving a prediction for both positive and negative edges.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "            lambda_reg (int, optional): The :math:`L_2` regularization strength\n",
    "                of the Bayesian Personalized Ranking (BPR) loss.\n",
    "                (default: :obj:`1e-4`)\n",
    "            **kwargs (optional): Additional arguments of the underlying\n",
    "                :class:`torch_geometric.nn.models.lightgcn.BPRLoss` loss\n",
    "                function.\n",
    "        \"\"\"\n",
    "        loss_fn = BPRLoss(lambda_reg, **kwargs)\n",
    "        emb = self.embedding.weight\n",
    "        emb = emb if node_id is None else emb[node_id]\n",
    "        return loss_fn(pos_edge_rank, neg_edge_rank, emb)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.num_nodes}, \" f\"{self.embedding_dim}, num_layers={self.num_layers})\"\n",
    "\n",
    "\n",
    "class BPRLoss(_Loss):\n",
    "    r\"\"\"The Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "    The BPR loss is a pairwise loss that encourages the prediction of an\n",
    "    observed entry to be higher than its unobserved counterparts\n",
    "    (see `here <https://arxiv.org/abs/2002.02126>`__).\n",
    "\n",
    "    .. math::\n",
    "        L_{\\text{BPR}} = - \\sum_{u=1}^{M} \\sum_{i \\in \\mathcal{N}_u}\n",
    "        \\sum_{j \\not\\in \\mathcal{N}_u} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})\n",
    "        + \\lambda \\vert\\vert \\textbf{x}^{(0)} \\vert\\vert^2\n",
    "\n",
    "    where :math:`lambda` controls the :math:`L_2` regularization strength.\n",
    "    We compute the mean BPR loss for simplicity.\n",
    "\n",
    "    Args:\n",
    "        lambda_reg (float, optional): The :math:`L_2` regularization strength\n",
    "            (default: 0).\n",
    "        **kwargs (optional): Additional arguments of the underlying\n",
    "            :class:`torch.nn.modules.loss._Loss` class.\n",
    "    \"\"\"\n",
    "    __constants__ = [\"lambda_reg\"]\n",
    "    lambda_reg: float\n",
    "\n",
    "    def __init__(self, lambda_reg: float = 0, **kwargs):\n",
    "        super().__init__(None, None, \"sum\", **kwargs)\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, positives: Tensor, negatives: Tensor, parameters: Tensor = None) -> Tensor:\n",
    "        r\"\"\"Compute the mean Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        .. note::\n",
    "\n",
    "            The i-th entry in the :obj:`positives` vector and i-th entry\n",
    "            in the :obj:`negatives` entry should correspond to the same\n",
    "            entity (*.e.g*, user), as the BPR is a personalized ranking loss.\n",
    "\n",
    "        Args:\n",
    "            positives (Tensor): The vector of positive-pair rankings.\n",
    "            negatives (Tensor): The vector of negative-pair rankings.\n",
    "            parameters (Tensor, optional): The tensor of parameters which\n",
    "                should be used for :math:`L_2` regularization\n",
    "                (default: :obj:`None`).\n",
    "        \"\"\"\n",
    "        log_prob = F.logsigmoid(positives - negatives).mean()\n",
    "\n",
    "        regularization = 0\n",
    "        if self.lambda_reg != 0:\n",
    "            regularization = self.lambda_reg * parameters.norm(p=2).pow(2)\n",
    "            regularization = regularization / positives.size(0)\n",
    "\n",
    "        return -log_prob + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36a46440-2736-4072-a621-9e3b9ebfb37c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 254077], num_nodes=3954, edge_weight=[254077], edge_label=[508154], edge_label_index=[2, 508154])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = RandomLinkSplit(num_val=0, num_test=0, add_negative_train_samples=True, neg_sampling_ratio=1.0)\n",
    "train_data, _, _ = transform(data)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2df151c6-eee9-485d-ad30-22e63562c044",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3923ee90bb4c8cbf2a6c543fe47ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : loss 0.7240769863128662\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "oof_pred = np.zeros(len(train_df))\n",
    "test_preds = []\n",
    "\n",
    "model = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=64,\n",
    "    num_layers=4,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in tqdm(range(1 if config.debug is False else 6)):\n",
    "    # train\n",
    "    pred = model.predict_link(\n",
    "        train_data.edge_index, train_data.edge_label_index, edge_weight=train_data.edge_weight, prob=True\n",
    "    )\n",
    "    loss = model.link_pred_loss(pred, train_data[\"edge_label\"])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch} : loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e3c4435-d715-46a8-942b-b7b6646a1425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectors = model.get_embedding(data.edge_index).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7800a2bc-54bb-4cab-ab14-90fb33bd2b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3954, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de5a36ac-2eea-4e81-b35e-45a2ff1e4bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3954, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors /= np.linalg.norm(vectors)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "881df46b-c314-48b4-bfe8-34a4ecc1eea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1998\n",
       "1         1999\n",
       "2         2000\n",
       "3         2001\n",
       "4         2002\n",
       "          ... \n",
       "254072    2184\n",
       "254073    3296\n",
       "254074    2427\n",
       "254075    3380\n",
       "254076    3900\n",
       "Name: anime_label, Length: 254077, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cc6a063-6ac1-4486-a274-b8ad171abfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_factors = vectors[: len(user_idx)]\n",
    "item_factors = vectors[len(user_idx) :]\n",
    "embeddings = np.concatenate(\n",
    "    (user_factors[all_df[\"user_label\"]], item_factors[(all_df[\"anime_label\"] - len(user_idx))]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d117d60-4f5d-4c84-b874-e32447459f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lightgcn_user_factor_0</th>\n",
       "      <th>lightgcn_user_factor_1</th>\n",
       "      <th>lightgcn_user_factor_2</th>\n",
       "      <th>lightgcn_user_factor_3</th>\n",
       "      <th>lightgcn_user_factor_4</th>\n",
       "      <th>lightgcn_user_factor_5</th>\n",
       "      <th>lightgcn_user_factor_6</th>\n",
       "      <th>lightgcn_user_factor_7</th>\n",
       "      <th>lightgcn_user_factor_8</th>\n",
       "      <th>lightgcn_user_factor_9</th>\n",
       "      <th>lightgcn_user_factor_10</th>\n",
       "      <th>lightgcn_user_factor_11</th>\n",
       "      <th>lightgcn_user_factor_12</th>\n",
       "      <th>lightgcn_user_factor_13</th>\n",
       "      <th>lightgcn_user_factor_14</th>\n",
       "      <th>lightgcn_user_factor_15</th>\n",
       "      <th>lightgcn_user_factor_16</th>\n",
       "      <th>lightgcn_user_factor_17</th>\n",
       "      <th>lightgcn_user_factor_18</th>\n",
       "      <th>lightgcn_user_factor_19</th>\n",
       "      <th>lightgcn_user_factor_20</th>\n",
       "      <th>lightgcn_user_factor_21</th>\n",
       "      <th>lightgcn_user_factor_22</th>\n",
       "      <th>lightgcn_user_factor_23</th>\n",
       "      <th>lightgcn_user_factor_24</th>\n",
       "      <th>...</th>\n",
       "      <th>lightgcn_item_factor_103</th>\n",
       "      <th>lightgcn_item_factor_104</th>\n",
       "      <th>lightgcn_item_factor_105</th>\n",
       "      <th>lightgcn_item_factor_106</th>\n",
       "      <th>lightgcn_item_factor_107</th>\n",
       "      <th>lightgcn_item_factor_108</th>\n",
       "      <th>lightgcn_item_factor_109</th>\n",
       "      <th>lightgcn_item_factor_110</th>\n",
       "      <th>lightgcn_item_factor_111</th>\n",
       "      <th>lightgcn_item_factor_112</th>\n",
       "      <th>lightgcn_item_factor_113</th>\n",
       "      <th>lightgcn_item_factor_114</th>\n",
       "      <th>lightgcn_item_factor_115</th>\n",
       "      <th>lightgcn_item_factor_116</th>\n",
       "      <th>lightgcn_item_factor_117</th>\n",
       "      <th>lightgcn_item_factor_118</th>\n",
       "      <th>lightgcn_item_factor_119</th>\n",
       "      <th>lightgcn_item_factor_120</th>\n",
       "      <th>lightgcn_item_factor_121</th>\n",
       "      <th>lightgcn_item_factor_122</th>\n",
       "      <th>lightgcn_item_factor_123</th>\n",
       "      <th>lightgcn_item_factor_124</th>\n",
       "      <th>lightgcn_item_factor_125</th>\n",
       "      <th>lightgcn_item_factor_126</th>\n",
       "      <th>lightgcn_item_factor_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>-0.001746</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>-0.001981</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>-0.002927</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>-0.002484</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>-0.002671</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>-0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.000982</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>-0.001505</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>-0.001866</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>-0.001736</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>-0.002181</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.001567</td>\n",
       "      <td>-0.001753</td>\n",
       "      <td>-0.001991</td>\n",
       "      <td>-0.001260</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.000641</td>\n",
       "      <td>0.001474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>-0.001980</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>-0.002772</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>-0.001898</td>\n",
       "      <td>-0.001861</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>-0.001084</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>-0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>-0.003166</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>-0.002706</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.003396</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-0.001335</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.001489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254072</th>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.002189</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.002923</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>-0.002523</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>-0.001669</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>-0.000675</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>-0.002569</td>\n",
       "      <td>-0.000526</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>-0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254073</th>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.002189</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.002923</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>-0.002523</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001350</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>-0.000780</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>-0.001494</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>-0.000776</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254074</th>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.002189</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.002923</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>-0.002523</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>-0.001585</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>-0.001484</td>\n",
       "      <td>-0.002601</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.000751</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>-0.002184</td>\n",
       "      <td>-0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254075</th>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.002189</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.002923</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>-0.002523</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>-0.001229</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>-0.001218</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>-0.001084</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254076</th>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.002189</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.002923</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>-0.002523</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>-0.001874</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>0.001476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254077 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lightgcn_user_factor_0  lightgcn_user_factor_1  \\\n",
       "0                     0.000435               -0.000651   \n",
       "1                     0.000435               -0.000651   \n",
       "2                     0.000435               -0.000651   \n",
       "3                     0.000435               -0.000651   \n",
       "4                     0.000435               -0.000651   \n",
       "...                        ...                     ...   \n",
       "254072               -0.000028               -0.000307   \n",
       "254073               -0.000028               -0.000307   \n",
       "254074               -0.000028               -0.000307   \n",
       "254075               -0.000028               -0.000307   \n",
       "254076               -0.000028               -0.000307   \n",
       "\n",
       "        lightgcn_user_factor_2  lightgcn_user_factor_3  \\\n",
       "0                     0.000225                0.000100   \n",
       "1                     0.000225                0.000100   \n",
       "2                     0.000225                0.000100   \n",
       "3                     0.000225                0.000100   \n",
       "4                     0.000225                0.000100   \n",
       "...                        ...                     ...   \n",
       "254072               -0.002189                0.001443   \n",
       "254073               -0.002189                0.001443   \n",
       "254074               -0.002189                0.001443   \n",
       "254075               -0.002189                0.001443   \n",
       "254076               -0.002189                0.001443   \n",
       "\n",
       "        lightgcn_user_factor_4  lightgcn_user_factor_5  \\\n",
       "0                     0.001384                0.000728   \n",
       "1                     0.001384                0.000728   \n",
       "2                     0.001384                0.000728   \n",
       "3                     0.001384                0.000728   \n",
       "4                     0.001384                0.000728   \n",
       "...                        ...                     ...   \n",
       "254072               -0.002923                0.002287   \n",
       "254073               -0.002923                0.002287   \n",
       "254074               -0.002923                0.002287   \n",
       "254075               -0.002923                0.002287   \n",
       "254076               -0.002923                0.002287   \n",
       "\n",
       "        lightgcn_user_factor_6  lightgcn_user_factor_7  \\\n",
       "0                    -0.001824               -0.000837   \n",
       "1                    -0.001824               -0.000837   \n",
       "2                    -0.001824               -0.000837   \n",
       "3                    -0.001824               -0.000837   \n",
       "4                    -0.001824               -0.000837   \n",
       "...                        ...                     ...   \n",
       "254072               -0.001104               -0.000928   \n",
       "254073               -0.001104               -0.000928   \n",
       "254074               -0.001104               -0.000928   \n",
       "254075               -0.001104               -0.000928   \n",
       "254076               -0.001104               -0.000928   \n",
       "\n",
       "        lightgcn_user_factor_8  lightgcn_user_factor_9  \\\n",
       "0                    -0.001304                0.002275   \n",
       "1                    -0.001304                0.002275   \n",
       "2                    -0.001304                0.002275   \n",
       "3                    -0.001304                0.002275   \n",
       "4                    -0.001304                0.002275   \n",
       "...                        ...                     ...   \n",
       "254072               -0.000424                0.000713   \n",
       "254073               -0.000424                0.000713   \n",
       "254074               -0.000424                0.000713   \n",
       "254075               -0.000424                0.000713   \n",
       "254076               -0.000424                0.000713   \n",
       "\n",
       "        lightgcn_user_factor_10  lightgcn_user_factor_11  \\\n",
       "0                      0.000646                -0.000460   \n",
       "1                      0.000646                -0.000460   \n",
       "2                      0.000646                -0.000460   \n",
       "3                      0.000646                -0.000460   \n",
       "4                      0.000646                -0.000460   \n",
       "...                         ...                      ...   \n",
       "254072                 0.000073                 0.000087   \n",
       "254073                 0.000073                 0.000087   \n",
       "254074                 0.000073                 0.000087   \n",
       "254075                 0.000073                 0.000087   \n",
       "254076                 0.000073                 0.000087   \n",
       "\n",
       "        lightgcn_user_factor_12  lightgcn_user_factor_13  \\\n",
       "0                      0.001808                 0.002445   \n",
       "1                      0.001808                 0.002445   \n",
       "2                      0.001808                 0.002445   \n",
       "3                      0.001808                 0.002445   \n",
       "4                      0.001808                 0.002445   \n",
       "...                         ...                      ...   \n",
       "254072                -0.001400                 0.000382   \n",
       "254073                -0.001400                 0.000382   \n",
       "254074                -0.001400                 0.000382   \n",
       "254075                -0.001400                 0.000382   \n",
       "254076                -0.001400                 0.000382   \n",
       "\n",
       "        lightgcn_user_factor_14  lightgcn_user_factor_15  \\\n",
       "0                      0.000127                 0.002651   \n",
       "1                      0.000127                 0.002651   \n",
       "2                      0.000127                 0.002651   \n",
       "3                      0.000127                 0.002651   \n",
       "4                      0.000127                 0.002651   \n",
       "...                         ...                      ...   \n",
       "254072                -0.001500                 0.001736   \n",
       "254073                -0.001500                 0.001736   \n",
       "254074                -0.001500                 0.001736   \n",
       "254075                -0.001500                 0.001736   \n",
       "254076                -0.001500                 0.001736   \n",
       "\n",
       "        lightgcn_user_factor_16  lightgcn_user_factor_17  \\\n",
       "0                      0.000657                 0.001603   \n",
       "1                      0.000657                 0.001603   \n",
       "2                      0.000657                 0.001603   \n",
       "3                      0.000657                 0.001603   \n",
       "4                      0.000657                 0.001603   \n",
       "...                         ...                      ...   \n",
       "254072                -0.002523                -0.001768   \n",
       "254073                -0.002523                -0.001768   \n",
       "254074                -0.002523                -0.001768   \n",
       "254075                -0.002523                -0.001768   \n",
       "254076                -0.002523                -0.001768   \n",
       "\n",
       "        lightgcn_user_factor_18  lightgcn_user_factor_19  \\\n",
       "0                      0.001061                 0.000752   \n",
       "1                      0.001061                 0.000752   \n",
       "2                      0.001061                 0.000752   \n",
       "3                      0.001061                 0.000752   \n",
       "4                      0.001061                 0.000752   \n",
       "...                         ...                      ...   \n",
       "254072                -0.002022                -0.001503   \n",
       "254073                -0.002022                -0.001503   \n",
       "254074                -0.002022                -0.001503   \n",
       "254075                -0.002022                -0.001503   \n",
       "254076                -0.002022                -0.001503   \n",
       "\n",
       "        lightgcn_user_factor_20  lightgcn_user_factor_21  \\\n",
       "0                     -0.001758                -0.000323   \n",
       "1                     -0.001758                -0.000323   \n",
       "2                     -0.001758                -0.000323   \n",
       "3                     -0.001758                -0.000323   \n",
       "4                     -0.001758                -0.000323   \n",
       "...                         ...                      ...   \n",
       "254072                -0.001620                 0.000147   \n",
       "254073                -0.001620                 0.000147   \n",
       "254074                -0.001620                 0.000147   \n",
       "254075                -0.001620                 0.000147   \n",
       "254076                -0.001620                 0.000147   \n",
       "\n",
       "        lightgcn_user_factor_22  lightgcn_user_factor_23  \\\n",
       "0                     -0.002247                -0.000240   \n",
       "1                     -0.002247                -0.000240   \n",
       "2                     -0.002247                -0.000240   \n",
       "3                     -0.002247                -0.000240   \n",
       "4                     -0.002247                -0.000240   \n",
       "...                         ...                      ...   \n",
       "254072                -0.000747                 0.000891   \n",
       "254073                -0.000747                 0.000891   \n",
       "254074                -0.000747                 0.000891   \n",
       "254075                -0.000747                 0.000891   \n",
       "254076                -0.000747                 0.000891   \n",
       "\n",
       "        lightgcn_user_factor_24  ...  lightgcn_item_factor_103  \\\n",
       "0                     -0.001351  ...                  0.001564   \n",
       "1                     -0.001351  ...                 -0.001093   \n",
       "2                     -0.001351  ...                 -0.000284   \n",
       "3                     -0.001351  ...                  0.001885   \n",
       "4                     -0.001351  ...                 -0.000688   \n",
       "...                         ...  ...                       ...   \n",
       "254072                -0.000942  ...                  0.000456   \n",
       "254073                -0.000942  ...                 -0.001350   \n",
       "254074                -0.000942  ...                  0.002128   \n",
       "254075                -0.000942  ...                  0.002247   \n",
       "254076                -0.000942  ...                 -0.001174   \n",
       "\n",
       "        lightgcn_item_factor_104  lightgcn_item_factor_105  \\\n",
       "0                      -0.000987                  0.002079   \n",
       "1                      -0.001788                  0.001001   \n",
       "2                       0.001137                 -0.001866   \n",
       "3                       0.001839                  0.002522   \n",
       "4                      -0.003166                  0.000797   \n",
       "...                          ...                       ...   \n",
       "254072                  0.000574                  0.000420   \n",
       "254073                 -0.002021                  0.002350   \n",
       "254074                  0.002762                  0.003372   \n",
       "254075                  0.001504                  0.002171   \n",
       "254076                  0.002362                 -0.000467   \n",
       "\n",
       "        lightgcn_item_factor_106  lightgcn_item_factor_107  \\\n",
       "0                      -0.001746                  0.000822   \n",
       "1                      -0.000982                  0.000895   \n",
       "2                       0.002506                  0.001189   \n",
       "3                       0.001556                 -0.000124   \n",
       "4                       0.000818                  0.000013   \n",
       "...                          ...                       ...   \n",
       "254072                 -0.000430                 -0.000417   \n",
       "254073                 -0.000780                  0.001533   \n",
       "254074                 -0.000576                  0.001729   \n",
       "254075                 -0.000527                 -0.001229   \n",
       "254076                 -0.001965                  0.001096   \n",
       "\n",
       "        lightgcn_item_factor_108  lightgcn_item_factor_109  \\\n",
       "0                       0.001040                 -0.001981   \n",
       "1                      -0.000173                 -0.002590   \n",
       "2                      -0.001736                 -0.001171   \n",
       "3                      -0.000747                  0.002635   \n",
       "4                       0.000786                  0.000949   \n",
       "...                          ...                       ...   \n",
       "254072                 -0.000715                 -0.001669   \n",
       "254073                  0.002706                  0.000072   \n",
       "254074                  0.002266                 -0.002173   \n",
       "254075                 -0.002396                 -0.001218   \n",
       "254076                  0.001479                 -0.001874   \n",
       "\n",
       "        lightgcn_item_factor_110  lightgcn_item_factor_111  \\\n",
       "0                       0.000092                 -0.000286   \n",
       "1                      -0.000009                 -0.001075   \n",
       "2                       0.001776                 -0.002368   \n",
       "3                       0.002480                  0.001213   \n",
       "4                       0.001538                 -0.002706   \n",
       "...                          ...                       ...   \n",
       "254072                  0.001855                 -0.000675   \n",
       "254073                 -0.000910                 -0.000178   \n",
       "254074                  0.001618                  0.000924   \n",
       "254075                 -0.000423                 -0.001500   \n",
       "254076                 -0.001068                 -0.000386   \n",
       "\n",
       "        lightgcn_item_factor_112  lightgcn_item_factor_113  \\\n",
       "0                       0.002543                  0.001307   \n",
       "1                       0.002726                 -0.000302   \n",
       "2                      -0.000995                 -0.002181   \n",
       "3                       0.000747                  0.001014   \n",
       "4                       0.000055                 -0.001768   \n",
       "...                          ...                       ...   \n",
       "254072                  0.001284                  0.001795   \n",
       "254073                 -0.000218                  0.000139   \n",
       "254074                 -0.001585                  0.000699   \n",
       "254075                  0.000716                 -0.000331   \n",
       "254076                 -0.001953                  0.002052   \n",
       "\n",
       "        lightgcn_item_factor_114  lightgcn_item_factor_115  \\\n",
       "0                      -0.000524                 -0.000107   \n",
       "1                       0.000289                  0.001854   \n",
       "2                       0.000659                  0.000050   \n",
       "3                      -0.001287                 -0.001980   \n",
       "4                       0.001463                  0.000096   \n",
       "...                          ...                       ...   \n",
       "254072                  0.000880                 -0.001531   \n",
       "254073                 -0.000345                 -0.000301   \n",
       "254074                  0.001050                  0.000829   \n",
       "254075                  0.000030                  0.001440   \n",
       "254076                  0.002474                  0.001231   \n",
       "\n",
       "        lightgcn_item_factor_116  lightgcn_item_factor_117  \\\n",
       "0                       0.002027                  0.000698   \n",
       "1                      -0.000094                 -0.000118   \n",
       "2                      -0.001567                 -0.001753   \n",
       "3                       0.000652                 -0.002772   \n",
       "4                       0.000274                 -0.003396   \n",
       "...                          ...                       ...   \n",
       "254072                  0.001650                  0.000222   \n",
       "254073                 -0.001494                 -0.000808   \n",
       "254074                  0.001467                 -0.000244   \n",
       "254075                  0.002151                 -0.000232   \n",
       "254076                 -0.000763                 -0.000510   \n",
       "\n",
       "        lightgcn_item_factor_118  lightgcn_item_factor_119  \\\n",
       "0                      -0.002927                  0.001641   \n",
       "1                      -0.002113                  0.000469   \n",
       "2                      -0.001991                 -0.001260   \n",
       "3                       0.001051                 -0.001898   \n",
       "4                       0.002390                 -0.000644   \n",
       "...                          ...                       ...   \n",
       "254072                 -0.002569                 -0.000526   \n",
       "254073                 -0.001803                 -0.000124   \n",
       "254074                  0.000501                  0.000077   \n",
       "254075                  0.000338                 -0.000385   \n",
       "254076                 -0.001943                 -0.001749   \n",
       "\n",
       "        lightgcn_item_factor_120  lightgcn_item_factor_121  \\\n",
       "0                      -0.001697                 -0.000899   \n",
       "1                       0.000201                 -0.000862   \n",
       "2                       0.002844                  0.002419   \n",
       "3                      -0.001861                  0.001989   \n",
       "4                       0.001989                  0.000202   \n",
       "...                          ...                       ...   \n",
       "254072                 -0.001276                 -0.000707   \n",
       "254073                  0.001243                 -0.000776   \n",
       "254074                  0.001617                 -0.001484   \n",
       "254075                  0.001085                 -0.000968   \n",
       "254076                 -0.000714                 -0.000493   \n",
       "\n",
       "        lightgcn_item_factor_122  lightgcn_item_factor_123  \\\n",
       "0                      -0.002484                  0.000198   \n",
       "1                       0.002007                 -0.001404   \n",
       "2                       0.000079                 -0.000103   \n",
       "3                       0.001299                  0.000614   \n",
       "4                      -0.001335                 -0.000213   \n",
       "...                          ...                       ...   \n",
       "254072                 -0.000494                 -0.000513   \n",
       "254073                  0.000104                  0.000587   \n",
       "254074                 -0.002601                  0.000154   \n",
       "254075                  0.001189                 -0.001084   \n",
       "254076                  0.002702                 -0.000102   \n",
       "\n",
       "        lightgcn_item_factor_124  lightgcn_item_factor_125  \\\n",
       "0                      -0.002671                  0.001865   \n",
       "1                      -0.001314                 -0.001505   \n",
       "2                      -0.000979                 -0.000213   \n",
       "3                      -0.001084                 -0.001275   \n",
       "4                      -0.000332                  0.001180   \n",
       "...                          ...                       ...   \n",
       "254072                 -0.000002                  0.001140   \n",
       "254073                  0.000102                 -0.001031   \n",
       "254074                 -0.000751                  0.000479   \n",
       "254075                  0.001774                  0.000378   \n",
       "254076                  0.000517                  0.001562   \n",
       "\n",
       "        lightgcn_item_factor_126  lightgcn_item_factor_127  \n",
       "0                       0.001271                 -0.000394  \n",
       "1                       0.000134                 -0.000992  \n",
       "2                      -0.000641                  0.001474  \n",
       "3                       0.002092                 -0.002343  \n",
       "4                       0.000483                 -0.001489  \n",
       "...                          ...                       ...  \n",
       "254072                 -0.001624                 -0.000933  \n",
       "254073                 -0.000239                 -0.000211  \n",
       "254074                 -0.002184                 -0.000362  \n",
       "254075                 -0.000237                 -0.000142  \n",
       "254076                 -0.000621                  0.001476  \n",
       "\n",
       "[254077 rows x 256 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "embeddings_df.columns = [f\"lightgcn_user_factor_{i}\" for i in range(user_factors.shape[1])] + [\n",
    "    f\"lightgcn_item_factor_{j}\" for j in range(item_factors.shape[1])\n",
    "]\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e417bb4-803c-4475-b104-da93ead0277a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1998, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21319aa0-c349-4e4a-bf6a-060a156238b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254077, 128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vectors[all_df[\"user_label\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff72b4b4-c374-4c5e-abae-13b475aa5066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1956, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e1865a-93c6-4c78-984a-d919b55b7a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "          ... \n",
       "254072    1997\n",
       "254073    1997\n",
       "254074    1997\n",
       "254075    1997\n",
       "254076    1997\n",
       "Name: user_label, Length: 254077, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[\"user_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "180aa38d-35cb-4bd9-90ca-132f2ed2593b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2070d5-83be-4a75-9ef3-6536f775790e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muser_vectors\u001b[49m[all_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_label\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_vectors' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d3d18-f862-4744-8a16-6c24ebbbc69d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
